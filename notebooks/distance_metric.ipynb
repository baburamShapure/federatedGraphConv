{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd054eb1c8ece2dcd35e7bc473e4bce3ae67a9168e9d916a4588e2494f3a286530c",
   "display_name": "Python 3.8.5 64-bit ('dl': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import numpy as np \n",
    "import networkx as nx \n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "# from prep_mhealth import prep_mhealth\n",
    "# from prep_wisdm import prep_wisdm\n",
    "from torch.nn import Linear \n",
    "import torch.optim as optim \n",
    "from torch_geometric.nn import GCNConv\n",
    "import time\n",
    "import tqdm \n",
    "import random\n",
    "import copy\n",
    "from torch_geometric.data import DataLoader\n",
    "# from model_utils import * \n",
    "import datetime as dttm \n",
    "import argparse\n",
    "from mlflow import log_metric, log_param, log_artifacts\n",
    "import mlflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('../scripts')\n",
    "from prep_mhealth import prep_mhealth\n",
    "from prep_wisdm import prep_wisdm\n",
    "from model_utils import * \n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\abhi\\\\Documents\\\\GEEK\\\\GNN\\\\ours'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import networkx as nx \n",
    "import matplotlib.colors as mcolors\n",
    "import random \n",
    "import scipy.spatial as sp \n",
    "import tqdm \n",
    "\n",
    "# datadir = 'data/WISDM_ar_v1.1'\n",
    "\n",
    "activity_map={}\n",
    "activity_map[1]='Walking'\n",
    "activity_map[2]='Jogging'\n",
    "activity_map[3]='Upstairs'\n",
    "activity_map[4]='Downstairs'\n",
    "activity_map[5]='Sitting'\n",
    "activity_map[6]='Standing'\n",
    "\n",
    "activity_map={}\n",
    "activity_map['Walking']=1\n",
    "activity_map['Jogging']=2 \n",
    "activity_map['Upstairs']= 3\n",
    "activity_map['Downstairs']= 4\n",
    "activity_map['Sitting']= 5\n",
    "activity_map['Standing'] = 6\n",
    "  \n",
    "\n",
    "def add_encoded_activity(filename, datadir, sep = \"\\t\"):\n",
    "    \"\"\"given raw user data \n",
    "    add the encoded activity column\n",
    "    \"\"\"\n",
    "    user_data = pd.read_csv(os.path.join(datadir, filename), \n",
    "                            sep = sep)\n",
    "    # print(user_data.shape)\n",
    "    colnames= ['user_id', 'activity', 'timestamp'] + ['feature_{}'.format(i) for i in range(1, 4)] \n",
    "    user_data.columns = colnames\n",
    "    user_data['encoded_activity'] =  user_data['activity'].map(activity_map)\n",
    "    # user_data['user_id'] = filename.split('_')[1].split('.')[0][7:]\n",
    "    user_data = user_data[['user_id', 'encoded_activity', 'feature_1', 'feature_2', 'feature_3']]\n",
    "\n",
    "    return user_data\n",
    "\n",
    "def average_slice(df_, NUM_SAMPLE = 128):\n",
    "    \"\"\"prepare time slices and \n",
    "    average over each time slice. \n",
    "    \"\"\"\n",
    "    out = []\n",
    "    num_groups = df_.shape[0] // NUM_SAMPLE\n",
    "    for i in range(0, df_.shape[0], NUM_SAMPLE): \n",
    "        idx = (i , min(df_.shape[0], i + NUM_SAMPLE))    \n",
    "        tmp = df_.iloc[idx[0]:idx[1], :]\n",
    "        averaged = pd.DataFrame(tmp.iloc[:, -3:].apply(np.mean)).T\n",
    "        out.append(pd.concat([averaged, tmp.iloc[:1, :-3].reset_index(drop = True)], axis = 1))\n",
    "    out = pd.concat(out)\n",
    "    out['encoded_activity'] = out['encoded_activity'].apply(int)\n",
    "    out.index = range(out.shape[0])\n",
    "    return out\n",
    "\n",
    "def prepare_graph(user_data, THRESHOLD = 3):\n",
    "    \"\"\"given the data for a user \n",
    "    prepare the graph. \n",
    "    \"\"\"\n",
    "    # print(user_data.head())\n",
    "    # prepare the distance matrix. \n",
    "    dist_mat = pd.DataFrame(sp.distance_matrix(user_data.iloc[:, :3].values, \n",
    "                                               user_data.iloc[:, :3].values))\n",
    "\n",
    "    cols = random.choices(list(mcolors.CSS4_COLORS.keys()), k =15)\n",
    "    cols_dict = {}\n",
    "    for i in range(1, 13):\n",
    "        cols_dict[i] = cols[i]\n",
    "\n",
    "    G = nx.Graph() \n",
    "    for i, row in user_data.iterrows(): \n",
    "        G.add_nodes_from([(i+1, {'features': row[:3]})])\n",
    "                        \n",
    "    for idx, row in dist_mat.iterrows(): \n",
    "        tmp = row.iloc[idx: ]\n",
    "        # all elements close to row. First is default by itself. \n",
    "        neighbors = list(tmp[tmp <= THRESHOLD].index)\n",
    "\n",
    "        for each_neighbor in neighbors[1: ]: \n",
    "            G.add_edge(idx, each_neighbor, weight = row[each_neighbor])\n",
    "\n",
    "    return G\n",
    "\n",
    "def write_node_attributes(G, dir): \n",
    "    __  = G.nodes.data()\n",
    "    with open(os.path.join(dir, 'node_attributes.txt'), 'w') as f: \n",
    "        for each_node in __ : \n",
    "            if len(each_node) > 0: \n",
    "                ftr = each_node[1]['features'].values\n",
    "                print(ftr)\n",
    "                for each_line in ftr: \n",
    "                    f.writeline(each_line)\n",
    "                f.writelines('\\n')\n",
    "    f.close()\n",
    "     \n",
    "def write_graph(G, dir): \n",
    "    \"\"\"\n",
    "    write a graph G into a directory dir. \n",
    "    \"\"\"\n",
    "    with open(os.path.join(dir, 'edge_list.txt'), 'w') as f :\n",
    "        for line in nx.generate_edgelist(G, delimiter = ',', data = False ):\n",
    "            f.writelines(line)\n",
    "            f.writelines('\\n')\n",
    "            f.writelines(','.join(line.split(',')[::-1]))\n",
    "            f.writelines('\\n')\n",
    "        f.close()\n",
    "\n",
    "def prep_wisdm(num_sample, dist_thresh, train_prop): \n",
    "    print('Preparing Data. ')\n",
    "    DATADIR = 'data\\WISDM'\n",
    "    for each_file in tqdm.tqdm(os.listdir(DATADIR)):\n",
    "        if each_file not in ['wisdm_subject'+str(i) for i in [4, 7, 16, 20, 33, 35 ]]:\n",
    "            # print(each_file)\n",
    "            user = each_file.split('_')[1].split('.')[0][7:] \n",
    "            tmp = add_encoded_activity(each_file, DATADIR, sep =',')\n",
    "            tmp1 = average_slice(tmp, num_sample)\n",
    "            gr = prepare_graph(tmp1, dist_thresh)\n",
    "\n",
    "            if user not in os.listdir('data\\processed\\wisdm'): \n",
    "                os.mkdir(os.path.join('data\\processed\\wisdm', user))\n",
    "            \n",
    "            tmp1.iloc[:, :3].to_csv(os.path.join('data\\processed\\wisdm', user, 'node_attributes' + '.txt'), \n",
    "                                    header = None, index = None)\n",
    "            # prepare training mask. \n",
    "            ar = pd.DataFrame(np.random.uniform(0, 1,   \n",
    "                                tmp1.shape[0]) >= 1 - train_prop, \n",
    "                                columns = ['train_mask'])\n",
    "\n",
    "            tmp1['encoded_activity'].to_csv(os.path.join('data\\processed\\wisdm', user, 'node_labels' + '.txt'), \n",
    "                                            header = None, index = None)\n",
    "            ar.to_csv(os.path.join('data\\processed\\wisdm', user, 'train_mask.txt'), \n",
    "                                            header = None, index = None)\n",
    "            write_graph(gr, os.path.join('data\\processed\\wisdm', user))\n",
    "    print('Data preparation finished. ')\n",
    "\n",
    "num_sample = 128\n",
    "dist_thresh = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 36/36 [00:30<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "DATADIR = 'data\\WISDM'\n",
    "counter = 1\n",
    "out = []\n",
    "for each_file in tqdm.tqdm(os.listdir(DATADIR)):\n",
    "    if each_file not in ['wisdm_subject'+str(i) for i in [4, 7, 16, 20, 33, 35 ]]:\n",
    "            user = each_file.split('_')[1].split('.')[0][7:] \n",
    "            tmp = add_encoded_activity(each_file, DATADIR, sep =',')\n",
    "            tmp1 = average_slice(tmp, num_sample)\n",
    "            out.append(tmp1)\n",
    "            # gr = prepare_graph(tmp1, dist_thresh)\n",
    "            # counter += 1\n",
    "            # if counter == 3: \n",
    "            #     break\n",
    "            # for i, grp in tmp1.groupby('encoded_activity'): \n",
    "            #     print(i)\n",
    "            #     dist_mat = pd.DataFrame(sp.distance.cdist(grp.iloc[:, :3].values, \n",
    "            #                             grp.iloc[:, :3].values,\n",
    "            #                             metric = 'mahalanobis'))\n",
    "            #     x = dist_mat.values.reshape(1,-1).ravel()\n",
    "            #     print(np.quantile(x, [0.5, 0.75, 0.9]))\n",
    "            #     print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.concat(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    feature_1  feature_2  feature_3  user_id  encoded_activity\n",
       "0    3.801953   9.931250  -0.510234        1                 1\n",
       "1    3.859609   9.889609  -0.556406        1                 1\n",
       "2    3.559687   9.974844  -0.704531        1                 1\n",
       "3    3.454062  10.361719  -0.654922        1                 1\n",
       "4    3.275781  10.053750  -0.509687        1                 1\n",
       "..        ...        ...        ...      ...               ...\n",
       "95  -7.918516   6.368281  -0.281797        1                 1\n",
       "96  -7.921172   6.595781  -0.326094        1                 1\n",
       "97  -8.019844   6.490156  -0.273047        1                 1\n",
       "98  -8.270703   6.349062   0.000391        1                 1\n",
       "99  -8.084922   6.306953  -0.268672        1                 1\n",
       "\n",
       "[100 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>user_id</th>\n      <th>encoded_activity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.801953</td>\n      <td>9.931250</td>\n      <td>-0.510234</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.859609</td>\n      <td>9.889609</td>\n      <td>-0.556406</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.559687</td>\n      <td>9.974844</td>\n      <td>-0.704531</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.454062</td>\n      <td>10.361719</td>\n      <td>-0.654922</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.275781</td>\n      <td>10.053750</td>\n      <td>-0.509687</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>-7.918516</td>\n      <td>6.368281</td>\n      <td>-0.281797</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>-7.921172</td>\n      <td>6.595781</td>\n      <td>-0.326094</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>-8.019844</td>\n      <td>6.490156</td>\n      <td>-0.273047</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>-8.270703</td>\n      <td>6.349062</td>\n      <td>0.000391</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>-8.084922</td>\n      <td>6.306953</td>\n      <td>-0.268672</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "finaldf.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8596, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "finaldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking = finaldf[finaldf['encoded_activity'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking_user1 = walking[walking['user_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     feature_1  feature_2  feature_3  user_id  encoded_activity\n",
       "0     3.801953   9.931250  -0.510234        1                 1\n",
       "1     3.859609   9.889609  -0.556406        1                 1\n",
       "2     3.559687   9.974844  -0.704531        1                 1\n",
       "3     3.454062  10.361719  -0.654922        1                 1\n",
       "4     3.275781  10.053750  -0.509687        1                 1\n",
       "..         ...        ...        ...      ...               ...\n",
       "135  -0.337500  10.204375  -0.148750        1                 1\n",
       "136   0.996094  10.686172  -0.263984        1                 1\n",
       "137   1.433437  10.531562  -0.298906        1                 1\n",
       "138   1.907422  10.755781  -0.060781        1                 1\n",
       "139   2.564922   9.236797   0.592344        1                 1\n",
       "\n",
       "[101 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>user_id</th>\n      <th>encoded_activity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.801953</td>\n      <td>9.931250</td>\n      <td>-0.510234</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.859609</td>\n      <td>9.889609</td>\n      <td>-0.556406</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.559687</td>\n      <td>9.974844</td>\n      <td>-0.704531</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.454062</td>\n      <td>10.361719</td>\n      <td>-0.654922</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.275781</td>\n      <td>10.053750</td>\n      <td>-0.509687</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>-0.337500</td>\n      <td>10.204375</td>\n      <td>-0.148750</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>0.996094</td>\n      <td>10.686172</td>\n      <td>-0.263984</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>1.433437</td>\n      <td>10.531562</td>\n      <td>-0.298906</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>1.907422</td>\n      <td>10.755781</td>\n      <td>-0.060781</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>2.564922</td>\n      <td>9.236797</td>\n      <td>0.592344</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>101 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "walking_user1"
   ]
  }
 ]
}